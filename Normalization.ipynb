{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different normalization processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### All the packages we need:\n",
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "from Reader import Reader\n",
    "from Randomforest import RandomForest_Autotunner,plot_matrix,Measure,check_rotate\n",
    "from Traj_creator import Traj_data\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os.path\n",
    "import cPickle as pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for files:\n",
    "- H2B_ NORMALISED OR NOT (N or U) _ DIFF or not ( D or F(fraction)) or 0 or A all\n",
    "Created files with orignal features $(X_t)_{t \\in \\textbf{N}}$ for a certain trajectory:\n",
    "- H2B_U (or H2B_U_F_0) : $v_t=X_t$\n",
    "- H2B_N_F_0 $v_t=\\frac{X_t}{X_0}$\n",
    "- H2B_N_F_A $v_t=\\frac{X_t}{\\bar{X}}$\n",
    "- H2B_N_D_0 $v_t=X_t-X_0$\n",
    "- H2B_N_D_A $v_t=X_t-\\bar{X}$ (Like in panel data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_str=\"0015\"  ## Well name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file existed so I loaded it.\n",
      "Traj_data built\n",
      "Reader constructed\n",
      "Updated member Group_of_traj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naylor/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:3006: DtypeWarning: Columns (245) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "## Well name\n",
    "\n",
    "if os.path.isfile(\"H2B_U_F_0.csv\"):\n",
    "    print \"The file existed so I loaded it.\"\n",
    "    H2B_U_F_0 = Traj_data(file_name=\"H2B_U_F_0.csv\")#,pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "    H2B_U_F_0.caract=\"Unnormalized\"\n",
    "\n",
    "else:    \n",
    "    H2B_U_F_0=Traj_data() \n",
    "\n",
    "    H2B_U_F_0.extracting(num_str,\"both_channels_0015.hdf5\",'primary') \n",
    "    ## Extracting the hdf5 file for the primary channel (H2b)\n",
    "\n",
    "    H2B_U_F_0.Add_traj(normalize=False,all_traj=False,average=False,diff=False)## ,num_traj=10) ## (you can reduce the number of traj)\n",
    "    ## Adding Alice's work on tracking to have trajectories\n",
    "\n",
    "    file_loc=\"0015_PCNA.xml\"\n",
    "\n",
    "    H2B_U_F_0.label_finder(file_loc) \n",
    "    ## Finding associated labels by minimizing distance by click and distance of cell\n",
    "\n",
    "    H2B_U_F_0.renaming_and_merge() \n",
    "    ## renaming the labels to have G1==\"1\", S==\"S\", G2==\"2\" and M==\"M\" \n",
    "    #This procedure may take a long time.\n",
    "    H2B_U_F_0.caract=\"Unnormalized\"\n",
    "    H2B_U_F_0.data.to_csv('H2B_U_F_0.csv',index=False,header=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file existed so I loaded it.\n",
      "Traj_data built\n",
      "Reader constructed\n",
      "Updated member Group_of_traj\n"
     ]
    }
   ],
   "source": [
    "## Well name\n",
    "\n",
    "if os.path.isfile(\"H2B_N_F_0.csv\"):\n",
    "    print \"The file existed so I loaded it.\"\n",
    "    H2B_N_F_0 = Traj_data(file_name=\"H2B_N_F_0.csv\")#,pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "    H2B_N_F_0.caract=\"Normalized by divided by first element\"\n",
    "else:    \n",
    "    H2B_N_F_0=Traj_data() \n",
    "\n",
    "    H2B_N_F_0.extracting(num_str,\"both_channels_0015.hdf5\",'primary') \n",
    "    ## Extracting the hdf5 file for the primary channel (H2b)\n",
    "    \n",
    "    H2B_N_.add_error() ## We had it so that the data won't have to do 0/0\n",
    "\n",
    "    H2B_N_F_0.Add_traj(normalize=True,all_traj=False,average=False,diff=False)## ,num_traj=10) ## (you can reduce the number of traj)\n",
    "    ## Adding Alice's work on tracking to have trajectories\n",
    "\n",
    "    file_loc=\"0015_PCNA.xml\"\n",
    "\n",
    "    H2B_N_F_0.label_finder(file_loc) \n",
    "    ## Finding associated labels by minimizing distance by click and distance of cell\n",
    "\n",
    "    H2B_N_F_0.renaming_and_merge() \n",
    "    ## renaming the labels to have G1==\"1\", S==\"S\", G2==\"2\" and M==\"M\" \n",
    "    #This procedure may take a long time.\n",
    "    H2B_N_F_0.caract=\"Normalized by divided by first element\"\n",
    "\n",
    "    H2B_N_F_0.data.to_csv('H2B_N_F_0.csv',index=False,header=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file existed so I loaded it.\n",
      "Traj_data built\n",
      "Reader constructed\n",
      "Updated member Group_of_traj\n"
     ]
    }
   ],
   "source": [
    "## Well name\n",
    "\n",
    "if os.path.isfile(\"H2B_N_D_0.csv\"):\n",
    "    print \"The file existed so I loaded it.\"\n",
    "    H2B_N_D_0 = Traj_data(file_name=\"H2B_N_D_0.csv\")#,pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "    H2B_N_D_0.caract=\"Normalized by subtracted by first element\"\n",
    "\n",
    "else:    \n",
    "    H2B_N_D_0=Traj_data()#(pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "\n",
    "    H2B_N_D_0.extracting(num_str,\"both_channels_0015.hdf5\",'primary') \n",
    "    ## Extracting the hdf5 file for the primary channel (H2b)\n",
    "    \n",
    "#    H2B_N_.add_error() ## We had it so that the data won't have to do 0/0\n",
    "\n",
    "    H2B_N_D_0.Add_traj(normalize=True,all_traj=False,average=False,diff=True)## ,num_traj=10) ## (you can reduce the number of traj)\n",
    "    ## Adding Alice's work on tracking to have trajectories\n",
    "\n",
    "    file_loc=\"0015_PCNA.xml\"\n",
    "\n",
    "    H2B_N_D_0.label_finder(file_loc) \n",
    "    ## Finding associated labels by minimizing distance by click and distance of cell\n",
    "\n",
    "    H2B_N_D_0.renaming_and_merge() \n",
    "    ## renaming the labels to have G1==\"1\", S==\"S\", G2==\"2\" and M==\"M\" \n",
    "    #This procedure may take a long time.\n",
    "    H2B_N_D_0.caract=\"Normalized by subtracted by first element\"\n",
    "\n",
    "    H2B_N_D_0.data.to_csv('H2B_N_D_0.csv',index=False,header=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file existed so I loaded it.\n",
      "Traj_data built\n",
      "Reader constructed\n",
      "Updated member Group_of_traj\n"
     ]
    }
   ],
   "source": [
    "## Well name\n",
    "\n",
    "if os.path.isfile(\"H2B_N_D_A.csv\"):\n",
    "    print \"The file existed so I loaded it.\"\n",
    "    H2B_N_D_A = Traj_data(file_name=\"H2B_N_D_A.csv\")#,pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "    H2B_N_D_A.caract=\"Normalized by subtracted by average\"\n",
    "\n",
    "else:    \n",
    "    H2B_N_D_A=Traj_data()#(pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "\n",
    "    H2B_N_D_A.extracting(num_str,\"both_channels_0015.hdf5\",'primary') \n",
    "    ## Extracting the hdf5 file for the primary channel (H2b)\n",
    "    \n",
    "#    H2B_N_D_A.add_error() ## We had it so that the data won't have to do 0/0\n",
    "\n",
    "    H2B_N_D_A.Add_traj(normalize=True,all_traj=True,average=True,diff=True)## ,num_traj=10) ## (you can reduce the number of traj)\n",
    "    ## Adding Alice's work on tracking to have trajectories\n",
    "\n",
    "    file_loc=\"0015_PCNA.xml\"\n",
    "\n",
    "    H2B_N_D_A.label_finder(file_loc) \n",
    "    ## Finding associated labels by minimizing distance by click and distance of cell\n",
    "\n",
    "    H2B_N_D_A.renaming_and_merge() \n",
    "    ## renaming the labels to have G1==\"1\", S==\"S\", G2==\"2\" and M==\"M\" \n",
    "    #This procedure may take a long time.\n",
    "    H2B_N_D_A.caract=\"Normalized by subtracted by average\"\n",
    "    \n",
    "    H2B_N_D_A.data.to_csv('H2B_N_D_A.csv',index=False,header=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file existed so I loaded it.\n",
      "Traj_data built\n",
      "Reader constructed\n",
      "Updated member Group_of_traj\n"
     ]
    }
   ],
   "source": [
    "## Well name\n",
    "\n",
    "if os.path.isfile(\"H2B_N_F_A.csv\"):\n",
    "    print \"The file existed so I loaded it.\"\n",
    "    H2B_N_F_A = Traj_data(file_name=\"H2B_N_F_A.csv\")#,pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "    H2B_N_F_A.caract=\"Normalized by dividing by average\"\n",
    "else:    \n",
    "    H2B_N_F_A=Traj_data()#(pkl_traj_file=\"/home/pubuntu/Documents/InternWork2/Pkl_file\") \n",
    "\n",
    "    H2B_N_F_A.extracting(num_str,\"both_channels_0015.hdf5\",'primary') \n",
    "    ## Extracting the hdf5 file for the primary channel (H2b)\n",
    "    \n",
    "#    H2B_N_F_A.add_error() ## We had it so that the data won't have to do 0/0\n",
    "\n",
    "    H2B_N_F_A.Add_traj(normalize=True,all_traj=True,average=True,diff=False)## ,num_traj=10) ## (you can reduce the number of traj)\n",
    "    ## Adding Alice's work on tracking to have trajectories\n",
    "\n",
    "    file_loc=\"0015_PCNA.xml\"\n",
    "\n",
    "    H2B_N_F_A.label_finder(file_loc) \n",
    "    ## Finding associated labels by minimizing distance by click and distance of cell\n",
    "\n",
    "    H2B_N_F_A.renaming_and_merge() \n",
    "    ## renaming the labels to have G1==\"1\", S==\"S\", G2==\"2\" and M==\"M\" \n",
    "    #This procedure may take a long time.\n",
    "    H2B_N_F_A.caract=\"Normalized by dividing by average\"\n",
    "\n",
    "    H2B_N_F_A.data.to_csv('H2B_N_F_A.csv',index=False,header=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granu_close_volume_3</th>\n",
       "      <th>dist_min</th>\n",
       "      <th>h4_2DAV</th>\n",
       "      <th>ch_variance_area</th>\n",
       "      <th>h4_2CON</th>\n",
       "      <th>0015_id_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.000583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.007310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.159021</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-0.000566</td>\n",
       "      <td>1.324555</td>\n",
       "      <td>-3.963971</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-113.162376</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>-0.000471</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-4.682632</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-127.418550</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>-0.000081</td>\n",
       "      <td>2.071068</td>\n",
       "      <td>-5.504165</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-141.654117</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     granu_close_volume_3  dist_min   h4_2DAV  ch_variance_area     h4_2CON  \\\n",
       "400              0.000000  0.000000  0.000000          0.000000    0.000000   \n",
       "473              0.000583  1.000000 -2.007310          0.000000  -66.159021   \n",
       "546             -0.000566  1.324555 -3.963971          0.222222 -113.162376   \n",
       "620             -0.000471  2.000000 -4.682632          0.888889 -127.418550   \n",
       "694             -0.000081  2.071068 -5.504165          0.250000 -141.654117   \n",
       "\n",
       "     0015_id_frame  \n",
       "400              5  \n",
       "473              6  \n",
       "546              7  \n",
       "620              8  \n",
       "694              9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_rand_index_train=(random.sample(H2B_N_D_0.train.index,5))\n",
    "_rand_col  = random.sample(H2B_N_D_0.names,5)\n",
    "traj=0\n",
    "obj=H2B_N_D_0\n",
    "obj.data.ix[obj.data[\"traj\"]==traj,_rand_col+[num_str+\"_id_frame\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granu_close_volume_3</th>\n",
       "      <th>dist_min</th>\n",
       "      <th>h4_2DAV</th>\n",
       "      <th>ch_variance_area</th>\n",
       "      <th>h4_2CON</th>\n",
       "      <th>0015_id_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>2.098451</td>\n",
       "      <td>1.320596</td>\n",
       "      <td>-112.277265</td>\n",
       "      <td>24.412672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000897</td>\n",
       "      <td>2.538758</td>\n",
       "      <td>0.247932</td>\n",
       "      <td>-111.527265</td>\n",
       "      <td>2.573731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.007043</td>\n",
       "      <td>2.098451</td>\n",
       "      <td>1.509869</td>\n",
       "      <td>-111.589765</td>\n",
       "      <td>30.757853</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.000210</td>\n",
       "      <td>1.317996</td>\n",
       "      <td>0.911806</td>\n",
       "      <td>-109.277265</td>\n",
       "      <td>15.029262</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.000812</td>\n",
       "      <td>1.098451</td>\n",
       "      <td>1.277300</td>\n",
       "      <td>-108.721709</td>\n",
       "      <td>26.567670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     granu_close_volume_3  dist_min   h4_2DAV  ch_variance_area    h4_2CON  \\\n",
       "0               -0.000002  2.098451  1.320596       -112.277265  24.412672   \n",
       "71               0.000897  2.538758  0.247932       -111.527265   2.573731   \n",
       "140              0.007043  2.098451  1.509869       -111.589765  30.757853   \n",
       "211              0.000210  1.317996  0.911806       -109.277265  15.029262   \n",
       "283             -0.000812  1.098451  1.277300       -108.721709  26.567670   \n",
       "\n",
       "     0015_id_frame  \n",
       "0                0  \n",
       "71               1  \n",
       "140              2  \n",
       "211              3  \n",
       "283              4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=H2B_N_D_A\n",
    "obj.data.ix[obj.data[\"traj\"]==traj,_rand_col+[num_str+\"_id_frame\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granu_close_volume_3</th>\n",
       "      <th>dist_min</th>\n",
       "      <th>h4_2DAV</th>\n",
       "      <th>ch_variance_area</th>\n",
       "      <th>h4_2CON</th>\n",
       "      <th>0015_id_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.000583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.007310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.159021</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-0.000566</td>\n",
       "      <td>1.324555</td>\n",
       "      <td>-3.963971</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-113.162376</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>-0.000471</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-4.682632</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-127.418550</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>-0.000081</td>\n",
       "      <td>2.071068</td>\n",
       "      <td>-5.504165</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-141.654117</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     granu_close_volume_3  dist_min   h4_2DAV  ch_variance_area     h4_2CON  \\\n",
       "400              0.000000  0.000000  0.000000          0.000000    0.000000   \n",
       "473              0.000583  1.000000 -2.007310          0.000000  -66.159021   \n",
       "546             -0.000566  1.324555 -3.963971          0.222222 -113.162376   \n",
       "620             -0.000471  2.000000 -4.682632          0.888889 -127.418550   \n",
       "694             -0.000081  2.071068 -5.504165          0.250000 -141.654117   \n",
       "\n",
       "     0015_id_frame  \n",
       "400              5  \n",
       "473              6  \n",
       "546              7  \n",
       "620              8  \n",
       "694              9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=H2B_N_D_0\n",
    "obj.data.ix[obj.data[\"traj\"]==traj,_rand_col+[num_str+\"_id_frame\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granu_close_volume_3</th>\n",
       "      <th>dist_min</th>\n",
       "      <th>h4_2DAV</th>\n",
       "      <th>ch_variance_area</th>\n",
       "      <th>h4_2CON</th>\n",
       "      <th>0015_id_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1.000582</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.826170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.999435</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>0.656726</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.437729</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.999530</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.594492</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>0.366895</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.999919</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.523348</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.296162</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     granu_close_volume_3  dist_min   h4_2DAV  ch_variance_area   h4_2CON  \\\n",
       "400              1.000000  1.000000  1.000000          1.000000  1.000000   \n",
       "473              1.000582  1.200000  0.826170          1.000000  0.671275   \n",
       "546              0.999435  1.264911  0.656726          1.222222  0.437729   \n",
       "620              0.999530  1.400000  0.594492          1.888889  0.366895   \n",
       "694              0.999919  1.414214  0.523348          1.250000  0.296162   \n",
       "\n",
       "     0015_id_frame  \n",
       "400              5  \n",
       "473              6  \n",
       "546              7  \n",
       "620              8  \n",
       "694              9  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=H2B_N_F_0\n",
    "obj.data.ix[obj.data[\"traj\"]==traj,_rand_col+[num_str+\"_id_frame\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granu_close_volume_3</th>\n",
       "      <th>dist_min</th>\n",
       "      <th>h4_2DAV</th>\n",
       "      <th>ch_variance_area</th>\n",
       "      <th>h4_2CON</th>\n",
       "      <th>0015_id_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999600</td>\n",
       "      <td>1.265575</td>\n",
       "      <td>1.216891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.376990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.162984</td>\n",
       "      <td>1.321299</td>\n",
       "      <td>1.040720</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>1.039745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2.279893</td>\n",
       "      <td>1.265575</td>\n",
       "      <td>1.247977</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>1.474975</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.038094</td>\n",
       "      <td>1.166802</td>\n",
       "      <td>1.149753</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>1.232088</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.852369</td>\n",
       "      <td>1.139017</td>\n",
       "      <td>1.209780</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>1.410268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     granu_close_volume_3  dist_min   h4_2DAV  ch_variance_area   h4_2CON  \\\n",
       "0                0.999600  1.265575  1.216891          0.000000  1.376990   \n",
       "71               1.162984  1.321299  1.040720          0.006680  1.039745   \n",
       "140              2.279893  1.265575  1.247977          0.006123  1.474975   \n",
       "211              1.038094  1.166802  1.149753          0.026720  1.232088   \n",
       "283              0.852369  1.139017  1.209780          0.031668  1.410268   \n",
       "\n",
       "     0015_id_frame  \n",
       "0                0  \n",
       "71               1  \n",
       "140              2  \n",
       "211              3  \n",
       "283              4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=H2B_N_F_A\n",
    "obj.data.ix[obj.data[\"traj\"]==traj,_rand_col+[num_str+\"_id_frame\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granu_close_volume_3</th>\n",
       "      <th>dist_min</th>\n",
       "      <th>h4_2DAV</th>\n",
       "      <th>ch_variance_area</th>\n",
       "      <th>h4_2CON</th>\n",
       "      <th>0015_id_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.001619</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.547558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>201.259640</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.002203</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.540248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.100619</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>6.324555</td>\n",
       "      <td>7.583587</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>88.097264</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.001149</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.864926</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>73.841090</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.001538</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>6.043393</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>59.605523</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     granu_close_volume_3  dist_min    h4_2DAV  ch_variance_area     h4_2CON  \\\n",
       "400              0.001619  5.000000  11.547558          0.000000  201.259640   \n",
       "473              0.002203  6.000000   9.540248          0.000000  135.100619   \n",
       "546              0.001053  6.324555   7.583587          0.222222   88.097264   \n",
       "620              0.001149  7.000000   6.864926          0.888889   73.841090   \n",
       "694              0.001538  7.071068   6.043393          0.250000   59.605523   \n",
       "\n",
       "     0015_id_frame  \n",
       "400              5  \n",
       "473              6  \n",
       "546              7  \n",
       "620              8  \n",
       "694              9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=H2B_U_F_0\n",
    "obj.data.ix[obj.data[\"traj\"]==traj,_rand_col+[num_str+\"_id_frame\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 51.921010 in sec\n",
      "Processing time: 53.324510 in sec\n",
      "Processing time: 53.556019 in sec\n",
      "Processing time: 55.268047 in sec\n",
      "Processing time: 53.992510 in sec\n"
     ]
    }
   ],
   "source": [
    "list_obj=[ H2B_U_F_0, H2B_N_F_A, H2B_N_F_0, H2B_N_D_A, H2B_N_D_0]\n",
    "kfold=3\n",
    "D={}\n",
    "instances_to_keep=H2B_N_F_0.train[pd.notnull(H2B_N_F_0.train.traj)].index\n",
    "for obj in list_obj:\n",
    "    if obj.Var_missing[0] in obj.train.columns:\n",
    "        obj.missing_features_train()\n",
    "    if obj.Var_missing[0] in obj.data.columns:\n",
    "        obj.missing_features_data()\n",
    "        \n",
    "    #instances_to_keep=pd.notnull(obj.train.traj)\n",
    "\n",
    "    values=[100 + i*10 for i in range(30)]\n",
    "\n",
    "    model=RandomForest_Autotunner(values)\n",
    "\n",
    "    model.tunning(obj.train.ix[instances_to_keep,obj.names],obj.train.ix[instances_to_keep,\"Type\"],kfold,plot=False,fit_new_model=True) #to get cm\n",
    "    plt.show()\n",
    "\n",
    "    i_=np.argmax(model.MSE)\n",
    "    n_tree=values[i_]\n",
    " ##   print \"For this caracteristic: \"+obj.caract +\", with n= \"+ str(sum(instances_to_keep)) +\"\\n\"\n",
    " ##   print \"We now have a classifier with n=%d, with an expected accuracy of %5.3f for the normalized data. \\n\" %(n_tree,max(model.MSE))\n",
    " ##   plot_matrix(model.cm,title=\"Confusion matrix unnormalized with normalized data\")\n",
    " ##   plt.show()\n",
    "    model.cm_normalized = model.cm.astype('float') / model.cm.sum(axis=1)[:, np.newaxis]\n",
    " ##   plot_matrix(model.cm_normalized,title=\"Confusion matrix normalized with normalized data\")\n",
    " ##   plt.show()\n",
    "    D[obj.caract]={\"tree_tunning\":n_tree,\n",
    "                   \"best accuracy\":max(model.MSE),\n",
    "                   \"Accuracy vector\":model.MSE,\n",
    "                   \"Confusion matrix\":model.cm,\n",
    "                   \"Normalized confusion matrix\":model.cm_normalized,\n",
    "                   \"Training sample\":str(obj.train.ix[instances_to_keep,obj.names].shape[0])\n",
    "                  }\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[161,   0,   3,  35],\n",
       "       [  0,   7,   1,  48],\n",
       "       [  1,   0,  35,   0],\n",
       "       [ 24,   5,   0, 188]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-25-b340fb7659bf>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-b340fb7659bf>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    n_tree=values[i_]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "i_=np.argmax(model.MSE)\n",
    "    n_tree=values[i_]\n",
    "    print \"For this caracteristic: \"+obj.caract +\", with n= \"+ str(sum(instances_to_keep)) +\"\\n\"\n",
    "    print \"We now have a classifier with n=%d, with an expected accuracy of %5.3f for the normalized data. \\n\" %(n_tree,max(model.MSE))\n",
    "    plot_matrix(model.cm,title=\"Confusion matrix unnormalized with normalized data\")\n",
    "    plt.show()\n",
    "    model.cm_normalized = model.cm.astype('float') / model.cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_matrix(model.cm_normalized,title=\"Confusion matrix normalized with normalized data\")\n",
    "    plt.show()\n",
    "    D[obj.caract]={\"tree_tunning\":n_tree,\n",
    "                   \"best accuracy\":max(model.MSE),\n",
    "                   \"Accuracy vector\":model.MSE,\n",
    "                   \"Confusion matrix\":model.cm,\n",
    "                   \"Normalized confusion matrix\":model.cm_normalized\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization process: Normalized by divided by first element\n",
      "Accuracy score: #####    0.777559055118   #####\n",
      "Effectif number: ####    508 \n",
      "\n",
      "Normalization process: Normalized by dividing by average\n",
      "Accuracy score: #####    0.724409448819   #####\n",
      "Effectif number: ####    508 \n",
      "\n",
      "Normalization process: Normalized by subtracted by average\n",
      "Accuracy score: #####    0.728346456693   #####\n",
      "Effectif number: ####    508 \n",
      "\n",
      "Normalization process: Unnormalized\n",
      "Accuracy score: #####    0.724409448819   #####\n",
      "Effectif number: ####    508 \n",
      "\n",
      "Normalization process: Normalized by subtracted by first element\n",
      "Accuracy score: #####    0.775590551181   #####\n",
      "Effectif number: ####    508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ke in D.keys():\n",
    "    tmp_dict=D[ke]\n",
    "    print \"Normalization process: \"+ke \n",
    "    print \"Accuracy score: #####    \"+str(tmp_dict[\"best accuracy\"])+\"   #####\"\n",
    "    print \"Effectif number: ####    \"+str(tmp_dict[\"Training sample\"])+\" \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best accuracy', 'tree_tunning', 'Accuracy vector', 'Normalized confusion matrix', 'Confusion matrix']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77952755905511806"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print tmp_dict.keys()\n",
    "tmp_dict[\"best accuracy\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
